#!/usr/bin/env python3
"""ë¨¸ì‹ ëŸ¬ë‹ ì˜ˆì¸¡ ëª¨ë¸ - ìˆ˜ì§‘ëœ ë°ì´í„° ê¸°ë°˜"""
import json
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path

def load_collected_data():
    """ìˆ˜ì§‘ëœ ì‹¤ì‹œê°„ ë°ì´í„° ë¡œë“œ"""
    data_file = Path("realtime_data.jsonl")
    if not data_file.exists():
        return []
    
    data = []
    with open(data_file, encoding="utf-8") as f:
        for line in f:
            try:
                data.append(json.loads(line))
            except:
                continue
    return data

def extract_features(data_point):
    """ë°ì´í„°ì—ì„œ íŠ¹ì„± ì¶”ì¶œ"""
    features = []
    
    # ì‹œê°„ íŠ¹ì„±
    features.append(data_point.get("hour", 0))
    features.append(data_point.get("minute", 0))
    features.append(data_point.get("weekday", 0))
    features.append(1 if data_point.get("is_weekend", False) else 0)
    
    # ë‚ ì”¨ íŠ¹ì„±
    weather = data_point.get("weather", {})
    if weather and not weather.get("error"):
        features.append(weather.get("temperature", 15))
        features.append(weather.get("humidity", 50))
        features.append(weather.get("impact_factor", 1.0))
        features.append(1 if weather.get("is_raining", False) else 0)
        features.append(1 if weather.get("is_snowing", False) else 0)
    else:
        features.extend([15, 50, 1.0, 0, 0])  # ê¸°ë³¸ê°’
    
    # êµí†µ íŠ¹ì„±
    traffic = data_point.get("traffic", {})
    for route in ["421", "400", "405"]:
        if route in traffic and "error" not in traffic[route]:
            features.append(traffic[route].get("estimated_headway", 10))
            features.append(traffic[route].get("next_bus", 5))
        else:
            features.extend([10, 5])  # ê¸°ë³¸ê°’
    
    return features

def simple_prediction_model(current_features):
    """ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ì˜ˆì¸¡ ëª¨ë¸"""
    hour, minute, weekday, is_weekend, temp, humidity, weather_impact, is_rain, is_snow = current_features[:9]
    
    # ê¸°ë³¸ í˜¼ì¡ë„ (ì‹œê°„ëŒ€ ê¸°ë°˜)
    if 6 <= hour <= 7:
        base_congestion = 0.3  # í•œì 
    elif 8 <= hour <= 9:
        base_congestion = 1.0  # ë§¤ìš° í˜¼ì¡
    elif 17 <= hour <= 19:
        base_congestion = 0.8  # í˜¼ì¡
    else:
        base_congestion = 0.5  # ë³´í†µ
    
    # ìš”ì¼ ë³´ì •
    if is_weekend:
        base_congestion *= 0.7  # ì£¼ë§ 30% ê°ì†Œ
    
    # ë‚ ì”¨ ë³´ì •
    base_congestion *= weather_impact
    
    # ì‹œê°„ ì„¸ë¶„í™” (ë¶„ ë‹¨ìœ„)
    if hour == 6 and minute < 30:
        base_congestion *= 0.8  # 06:00-06:30 ë” í•œì 
    elif hour == 8 and 10 <= minute <= 30:
        base_congestion *= 1.2  # 08:10-08:30 í”¼í¬
    
    return min(base_congestion, 2.0)  # ìµœëŒ€ 2ë°°

def predict_congestion():
    """í˜„ì¬ ì‹œì  í˜¼ì¡ë„ ì˜ˆì¸¡"""
    now = datetime.now()
    
    # í˜„ì¬ íŠ¹ì„± ìƒì„±
    current_features = [
        now.hour,
        now.minute,
        now.weekday(),
        1 if now.weekday() >= 5 else 0,
        15, 50, 1.0, 0, 0,  # ê¸°ë³¸ ë‚ ì”¨ê°’ (ì‹¤ì œë¡œëŠ” APIì—ì„œ)
        10, 5, 10, 5, 10, 5  # ê¸°ë³¸ êµí†µê°’
    ]
    
    predicted_congestion = simple_prediction_model(current_features)
    
    # ì˜ˆì¸¡ ì‹ ë¢°ë„ ê³„ì‚°
    data = load_collected_data()
    confidence = min(len(data) / 100, 1.0)  # ë°ì´í„° ë§ì„ìˆ˜ë¡ ì‹ ë¢°ë„ ì¦ê°€
    
    return {
        "predicted_congestion": round(predicted_congestion, 2),
        "confidence": round(confidence, 2),
        "recommendation": get_ml_recommendation(predicted_congestion),
        "data_points": len(data)
    }

def get_ml_recommendation(congestion):
    """ML ê¸°ë°˜ ì¶”ì²œ"""
    if congestion < 0.4:
        return "ğŸŸ¢ ë§¤ìš° í•œì  - ì§€ê¸ˆì´ ìµœì  ì‹œê°„"
    elif congestion < 0.7:
        return "ğŸŸ¡ ë³´í†µ - ê´œì°®ì€ ì‹œê°„"
    elif congestion < 1.2:
        return "ğŸŸ  í˜¼ì¡ - ê°€ëŠ¥í•˜ë©´ í”¼í•˜ì„¸ìš”"
    else:
        return "ğŸ”´ ë§¤ìš° í˜¼ì¡ - ë‹¤ë¥¸ ì‹œê°„ ì¶”ì²œ"

def analyze_patterns():
    """ìˆ˜ì§‘ëœ ë°ì´í„° íŒ¨í„´ ë¶„ì„"""
    data = load_collected_data()
    if len(data) < 10:
        return {"error": "ë¶„ì„í•˜ê¸°ì— ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤"}
    
    # ì‹œê°„ëŒ€ë³„ í‰ê·  ê³„ì‚°
    hourly_patterns = {}
    for item in data:
        hour = item.get("hour", 0)
        if hour not in hourly_patterns:
            hourly_patterns[hour] = []
        
        # ë²„ìŠ¤ ìˆ˜ ê³„ì‚°
        bus_count = len(item.get("buses", []))
        hourly_patterns[hour].append(bus_count)
    
    # í‰ê·  ê³„ì‚°
    hourly_avg = {}
    for hour, counts in hourly_patterns.items():
        hourly_avg[hour] = round(np.mean(counts), 1)
    
    return {
        "hourly_average": hourly_avg,
        "total_data_points": len(data),
        "analysis_period": f"{len(data) * 10}ë¶„ê°„ ìˆ˜ì§‘"
    }

if __name__ == "__main__":
    print("=== ë¨¸ì‹ ëŸ¬ë‹ ì˜ˆì¸¡ ëª¨ë¸ ===")
    
    prediction = predict_congestion()
    print(f"í˜„ì¬ í˜¼ì¡ë„ ì˜ˆì¸¡: {prediction['predicted_congestion']}ë°°")
    print(f"ì˜ˆì¸¡ ì‹ ë¢°ë„: {prediction['confidence']*100:.0f}%")
    print(f"ì¶”ì²œ: {prediction['recommendation']}")
    print(f"í•™ìŠµ ë°ì´í„°: {prediction['data_points']}ê°œ")
    
    print("\n=== íŒ¨í„´ ë¶„ì„ ===")
    patterns = analyze_patterns()
    if "error" not in patterns:
        print(f"ë¶„ì„ ê¸°ê°„: {patterns['analysis_period']}")
        print("ì‹œê°„ëŒ€ë³„ í‰ê·  ë²„ìŠ¤ ìˆ˜:")
        for hour in sorted(patterns['hourly_average'].keys()):
            avg = patterns['hourly_average'][hour]
            print(f"  {hour:02d}ì‹œ: {avg}ëŒ€")
